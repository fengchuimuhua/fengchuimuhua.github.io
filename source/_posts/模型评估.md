---
title: （二）模型评估
date: 2019-12-04 00:44:11
tags: [Model Evaluation, 模型评估]
mathjax: true
---

如何评估一个模型是好是坏？在分类问题中，我们最常听说的PR曲线是什么？我们听到的Roc曲线又是什么呢？到底我们是该用Roc曲线还是PR曲线去衡量一个二分类模型的好坏呢？本文在介绍模型评估的基本概念的同时，也将回答上述问题。

<!-- more -->

## 精确度(Precision)、召回率(Recall) 与 准确率(Accuracy)

![](/images/pr/pr1.png)
<div class="image-caption" style="margin: 6 auto;">
  <span class="image-caption" style="margin: 4 auto ">图1：精确度、召回率和准确率</span>
</div>

&#8194;&#8194;&#8194;&#8194;精确度(Precision)和召回率(Recall)用来评估二分类模型，精确度(Accuracy)既可以用来评估二分类模型的效果，也可以评估多分类模型。其中，精确度(Precision)的定义为：$Precision=\frac{TP}{TP+FP}$，也就是我们用训练好的二分类模型判断出数据集（这里的数据集指验证集，专门用来评估模型是好是坏的带有label的数据集）的正样本中真实的正样本所占的比例。召回率(Recall)的定义为：$Recall=\frac{TP}{TP+FN}$，也就是模型分类结果中标为正样本的sample个数占数据集中真实正样本个数的比例。准确率(Accuracy)的概念相对更加直接：$Accuracy=\frac{TP+TN}{TP+TN+FP+FN}$，也就是说分类器对数据集分类正确的样本占样本全集的比例。大家也可以参照上图理解这三个概念。

&#8194;&#8194;&#8194;&#8194;在学校学习的时候或者在Coursera、Edx、学堂在线这些平台上看一些公开课的时候，用的比较多的是准确率(Accuracy)这个概念，但是本人在“算法工程师”的日常工作中，用到的更多的却是精确度(Precision)和召回率(Recall)这两个概念。这是为什么呢？我的理解如下：

1. 工业界实际数据与courses或者papers的数据集存在差异：在课程或者论文中的数据集，很大一部分都是样本均衡的数据集，因为我们focus在模型上，而非具体的数据，也不必完全贴近真实场景下的数据分布。举个具体的例子，我在学习深度学习图像识别的时候，评估CNN模型一般都是使用CIFA10或者ImageNet这样非常“标准”的数据集，CIFA10中包含10个类别（当然也确实没法直接使用精确度和召回率来评估，除非用one-vs-rest这种方法），每个类别下的样本个数基本一致，此时准确率(Accuracy)已经完全能够评估模型是好是坏。而在工业场景中，例如转化率预估场景，数据集的正负样本差异极大，这时候如果直接用准确率评估则毫无意义。假如点击率预估数据集中正样本比例为$0.2\%$，负样本比例为$99.8\%$，那么即使模型把所有的样本都预测为负，模型的准确率也能达到$99.8\%$。在这个场景下谈准确率意义不大。

2. 模型的精确度、召回率亦或是准确率都和我们设置的阈值有关（模型会给出一个待预测sample为正的概率，最终判断该样本为正为负通过判断概率值与阈值的大小关系进行），在工业界中一般都会结合具体业务场景去决策阈值的设置：比如一个人脸身份验证系统，我们往往需要保证系统的可靠性，这时候往往需要通过设置较高的阈值，保证“验证通过”这样的正样本具有很高的精确度。再比如，如果你要设计一个自动识别bug的系统，这时候对系统的要求则可能是尽可能找到所有的bug，此时需要设置相对较低的阈值以保证识别结果的高召回。

&#8194;&#8194;&#8194;&#8194;我自己在日常“算法工程师”的工作中，一般的工作流程是，对训练好的模型画出它的PR曲线（下面将会介绍），结合业务需要在这个PR曲线上找到一个合适的点（即确定阈值），评估模型的准确率使用相对低频。

## PR曲线和Roc曲线

### PR曲线

&#8194;&#8194;&#8194;&#8194;PR曲线的全称是Precision-Recall曲线，顾名思义组成该曲线的点的坐标由`召回率`和`精确率`组成。在学习的逻辑斯蒂回归(Logistic Regression)时，我们知道逻辑斯蒂函数（Logistic Function，函数形式为$f(x)=\frac{1}{1+e^{-x}}$）将会计算出一个位于$(0,1)$区间之内的值，并且将该值作为样本归属正样本集的概率值$p(x=1)$。但正如前文所说，我们要视情况决定我们采取什么样的`判断阈值`threshold（当$p(x)\geq threshold$时，将样本预测为正样本，反之当$p(x)<threshold$时，将样本预测为负样本）。所以，我们需要看模型在不同的阈值下的精确和召回情况。PR曲线一般以召回率作为横轴，精确率作为纵轴绘制，刻画出模型在不同的召回情况下的精确程度。

&#8194;&#8194;&#8194;&#8194;PR曲线一方面让模型在不同召回率下的精确度一眼就看出来，另一方面使得模型对比更加充分。图中包含模型A和模型B两个模型的准召曲线，可以看出当召回比较少时模型B的精确度能达到1.0，要与模型A在召回较少时的精确度。但当召回较大时模型B的精确度指标却弱于模型A。这说明仅仅取一个$(precision, recall)$点来评估模型是不够的，从PR曲线分析模型更能全面了解模型在不同的召回下的表现。

<img src="/images/pr/pr2.png" width="50%" height="50%" border="0" style="margin: 0 auto;"/>
<div class="image-caption" style="margin: 6 auto;">
  <span class="image-caption" style="margin: 4 auto ">图2：两个模型的准召曲线</span>
</div>


### ROC曲线

### 什么时候用PR曲线，什么时候用ROC曲线？
